""" This module contains the Model class for the GPT model."""

from dataclasses import dataclass, field
import logging as log
from typing import List, Dict, Any
import re
import asyncio
import aiohttp
from requests import head
from .enums import ResponseStatus


@dataclass
class Model:
    """
    Configuration class for the GPT model.

    Attributes:
        gpt_api_key (str): The API key for the GPT model.
        gpt_base_url (str): The base URL for the GPT model.
        model (str): The name of the GPT model.
        models (List[Dict[str, Any]]): A list of available GPT models.
    """

    api_key: str
    url: str
    model_name: str
    model: Dict[str, Any]
    models: List[Dict[str, Any]]

    def __init__(self, key: str, url: str, model_name: str, use_model: bool = True):
        self.api_key = key
        self.url = url
        self.model_name = model_name
        self.use_model = use_model
        self.models = [
            {"Name": "gpt-3.5-turbo", "Tokens": 4096},
            {"Name": "gpt-3.5-turbo-16k", "Tokens": 16385},
            {"Name": "gpt-4", "Tokens": 8192},
            {"Name": "gpt-4-32k", "Tokens": 32768},
            {"Name": "gpt-4o", "Tokens": 128000},
        ]
        self.model = next((m for m in self.models if m["Name"] == self.model_name))
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

    async def summarise(self, prompt: str, session: aiohttp.ClientSession) -> str:
        """
        Sends a prompt to GPT and returns the response.

        Args:
            prompt (str): The prompt to be sent to GPT.

        Returns:
            str: The response generated by GPT.
        """
        token_count = self.count_tokens(prompt)
        if self.model and token_count > self.model["Tokens"]:
            log.warning(
                "The prompt contains too many tokens for the selected model %s/%s. Please reduce the size of the prompt.",
                token_count,
                self.model["Tokens"],
            )
            return ""

        retry_count = 0
        initial_delay = 10
        max_retries = 6
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
        }
        uri = f"{self.url}/chat/completions"

        async with session.get(uri, headers=self.headers, timeout=10) as response:
            async with session.post(
                f"{self.url}/chat/completions",
                json=payload,
            ) as response:
                result = await response.json()
                if response.status != 200:
                    log.error(result["error"]["message"])
                return str(result["choices"][0]["message"]["content"])

    def count_tokens(self, text: str) -> int:
        """
        Calculates the token count for a given text.

        Parameters:
        text (str): The input text for which the token count needs to be calculateDevOpsConfig.

        Returns:
        int: The total count of tokens in the given text.
        """
        word_count = len(re.findall(r"\b\w+\b", text))
        char_count = len(re.sub(r"\s", "", text))
        return word_count + char_count
